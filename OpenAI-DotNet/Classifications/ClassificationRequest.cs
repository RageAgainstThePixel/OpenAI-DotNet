using System.Collections.Generic;
using System.Linq;
using System.Text.Json.Serialization;

namespace OpenAI_DotNet
{
    /// <summary>
    /// Represents a request to the Classification API.  Mostly matches the parameters in
    /// <see href="https://beta.openai.com/docs/api-reference/classifications">the OpenAI docs</see>,
    /// although some have been removed since we don't support file upload yet.
    /// </summary>
    public sealed class ClassificationRequest
    {
        /// <summary>
        /// Query to be classified.
        /// </summary>
        [JsonPropertyName("query")]
        public string Query { get; }

        /// <summary>
        /// A list of examples with labels.
        /// All the label strings will be normalized to be capitalized.
        /// </summary>
        [JsonPropertyName("examples")]
        public IReadOnlyList<IReadOnlyList<string>> Examples { get; }

        /// <summary>
        /// The set of categories being classified. If not specified,
        /// candidate labels will be automatically collected from the examples you provide.
        /// All the label strings will be normalized to be capitalized.
        /// </summary>
        [JsonPropertyName("labels")]
        public IReadOnlyList<string> Labels { get; }

        [JsonPropertyName("model")]
        public string CompletionModel => CompletionEngine.EngineName;

        /// <summary>
        /// The <see cref="Engine"/> to use for completion. Defaults to <see cref="Engine.Davinci"/>.
        /// </summary>
        [JsonIgnore]
        public Engine CompletionEngine { get; }

        [JsonPropertyName("search_model")]
        public string SearchModel => SearchEngine.EngineName;

        /// <summary>
        /// The <see cref="Engine"/> to use for searching. Defaults to <see cref="Engine.Ada"/>.
        /// </summary>
        [JsonIgnore]
        public Engine SearchEngine { get; }

        /// <summary>
        /// What sampling temperature to use.
        /// Higher values mean the model will take more risks.
        /// Try 0.9 for more creative applications, and 0 (argmax sampling) for ones with a well-defined answer.
        /// Defaults to 0.
        /// </summary>
        [JsonPropertyName("temperature")]
        public double? Temperature { get; }

        /// <summary>
        /// Include the log probabilities on the logprobs most likely tokens,
        /// as well the chosen tokens. For example, if logprobs is 10, the API will return a list of the 10 most likely tokens.
        /// the API will always return the logprob of the sampled token, so there may be up to logprobs+1 elements in the response.
        /// When logprobs is set, completion will be automatically added into expand to get the logprobs.
        /// </summary>
        [JsonPropertyName("logprobs")]
        public int? LogProbabilities { get; }

        /// <summary>
        /// Modify the likelihood of specified tokens appearing in the completion.
        /// Accepts a json object that maps tokens (specified by their token ID in the GPT tokenizer) to an associated bias value from -100 to 100.
        /// You can use this tokenizer tool <see href="https://beta.openai.com/tokenizer?view=bpe"/>
        /// (which works for both GPT-2 and GPT-3) to convert text to token IDs.
        /// Mathematically, the bias is added to the logits generated by the model prior to sampling.
        /// The exact effect will vary per model, but values between -1 and 1 should decrease or increase likelihood of selection;
        /// values like -100 or 100 should result in a ban or exclusive selection of the relevant token.
        /// As an example, you can pass {"50256": -100} to prevent the &lt;|endoftext|&gt; token from being generated.
        /// </summary>
        [JsonPropertyName("logit_bias")]
        public IReadOnlyDictionary<string, int> LogitBias { get; }

        /// <summary>
        /// If set to true, the returned JSON will include a "prompt" field containing the final prompt
        /// that was used to request a completion. This is mainly useful for debugging purposes.
        /// </summary>
        [JsonPropertyName("return_prompt")]
        public bool ReturnPrompt { get; }

        /// <summary>
        /// Classifies the specified query using provided examples.
        /// </summary>
        /// <param name="query">Query to be classified.</param>
        /// <param name="examples">A list of examples with labels, in the following format:
        /// [["The movie is so interesting.", "Positive"], ["It is quite boring.", "Negative"], ...]
        /// All the label strings will be normalized to be capitalized.</param>
        /// <param name="labels">The set of categories being classified. If not specified,
        /// candidate labels will be automatically collected from the examples you provide.
        /// All the label strings will be normalized to be capitalized.</param>
        /// <param name="completionEngine">The <see cref="Engine"/> to use for completion. Defaults to <see cref="Engine.Default"/>.</param>
        /// <param name="searchEngine">The <see cref="Engine"/> to use for searching. Defaults to <see cref="Engine.Ada"/>.</param>
        /// <param name="temperature">What sampling temperature to use.
        /// Higher values mean the model will take more risks.
        /// Try 0.9 for more creative applications, and 0 (argmax sampling) for ones with a well-defined answer.
        /// Defaults to 0.</param>
        /// <param name="logProbabilities">Include the log probabilities on the logprobs most likely tokens,
        /// as well the chosen tokens. For example, if logprobs is 10, the API will return a list of the 10 most likely tokens.
        /// the API will always return the logprob of the sampled token, so there may be up to logprobs+1 elements in the response.
        /// When logprobs is set, completion will be automatically added into expand to get the logprobs.</param>
        /// <param name="logitBias">Modify the likelihood of specified tokens appearing in the completion.
        /// Accepts a json object that maps tokens (specified by their token ID in the GPT tokenizer) to an associated bias value from -100 to 100.
        /// You can use this tokenizer tool <see href="https://beta.openai.com/tokenizer?view=bpe"/>
        /// (which works for both GPT-2 and GPT-3) to convert text to token IDs.
        /// Mathematically, the bias is added to the logits generated by the model prior to sampling.
        /// The exact effect will vary per model, but values between -1 and 1 should decrease or increase likelihood of selection;
        /// values like -100 or 100 should result in a ban or exclusive selection of the relevant token.
        /// As an example, you can pass {"50256": -100} to prevent the &lt;|endoftext|&gt; token from being generated.</param>
        /// <param name="returnPrompt">If set to true, the returned JSON will include a "prompt" field containing the final prompt
        /// that was used to request a completion. This is mainly useful for debugging purposes.</param>
        public ClassificationRequest(string query, IReadOnlyDictionary<string, string> examples,
            IEnumerable<string> labels = null,
            Engine completionEngine = null,
            Engine searchEngine = null,
            double? temperature = null,
            int? logProbabilities = null,
            IReadOnlyDictionary<string, int> logitBias = null,
            bool returnPrompt = false)
        {
            Query = query;

            var tempExamples = new List<List<string>>(examples.Count);

            foreach (var (key, value) in examples)
            {
                tempExamples.Add(new List<string> { key, value });
            }

            Examples = tempExamples;
            Labels = labels?.ToList() ?? new List<string>();
            CompletionEngine = completionEngine ?? Engine.Default;
            SearchEngine = searchEngine ?? Engine.Ada;
            Temperature = temperature;
            LogProbabilities = logProbabilities;
            LogitBias = logitBias;
            ReturnPrompt = returnPrompt;
        }
    }
}